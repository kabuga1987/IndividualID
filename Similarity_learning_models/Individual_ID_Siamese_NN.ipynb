{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab715521",
   "metadata": {},
   "source": [
    "We used four different datasets (species) to validate our developed approach; therefore, we ran four separate models using the same architectures (each model per dataset). The script **Individual_ID_Siamese_NN_helper.py** contains all the required implementations to run the the similarity learning network based on the Siamese neural network. Here we provide four subsets of the datasets we used in the paper and csv files containing image names and their corresponding IDs where images having the same ID originate from the same individual, otherwise two different individuals. For e.g. p2 and p1 refer to the directory containing whale image examples and the csv file containing their IDs.\n",
    "\n",
    "Parameters\n",
    "\n",
    "1. nIms: The most number of images from each individual used in the baatch of images,\n",
    "2. shp: The size of the input image,\n",
    "3. augmentation: The number of augmented versions of the original images to be generated during online data augmentation,\n",
    "4. Lr: Maximum learning rate,\n",
    "5. lr: Minimum learning rate,\n",
    "6. n: An equal number of matches and non-matches to generate from the test set for the sake of evaluating the verification task,\n",
    "7. Epochs: The number of iteration to train the model,\n",
    "8. compress_horizontal: A boolean parameter only set to **True** for the whale dataset.\n",
    "9. pm: Path for saving weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ab594a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 10:09:10.647359: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from Individual_ID_Siamese_NN_helper import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5cce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"whale_image_examples_IDs.csv\"\n",
    "p2 = \"whale_image_examples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950c4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nIms = 4\n",
    "shp   = (384,384,1)\n",
    "augmentation = 4\n",
    "Lr = 2e-3\n",
    "lr = 5e-4\n",
    "pm = \"Path_save_weights.h5\"\n",
    "n = 5\n",
    "Epochs = 2\n",
    "compress_horizontally = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56bead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structuring\n",
    "Ds = DataStructuring(p1,p2,nIms)\n",
    "Imgs,Labels = Ds.Im2Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a035f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data spliting into training, validation, and test sets\n",
    "sp = 8\n",
    "v = 16\n",
    "TIms,TLabs = Imgs[:sp],Labels[:sp]\n",
    "VIms,VLabs = Imgs[sp:v],Labels[sp:v]\n",
    "TeIms,TeLabs = Imgs[v:],Labels[v:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041fc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation, creating copies of the original sets and modify them during training\n",
    "# using an affine transformation\n",
    "TIms, TLabs = Augmentation(TIms,TLabs,augmentation,nIms).Im2Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd3e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 1806.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 24 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-11-28 10:09:28.871652: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-28 10:09:29.704110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-11-28 10:09:29.704152: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-28 10:09:29.710219: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-11-28 10:09:29.710293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-28 10:09:29.712624: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-28 10:09:29.713246: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-28 10:09:29.713979: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-11-28 10:09:29.715070: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-11-28 10:09:29.715431: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-11-28 10:09:29.715948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-28 10:09:29.716894: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 10:09:29.726663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-11-28 10:09:29.727061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-28 10:09:29.727096: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-28 10:09:30.264621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-28 10:09:30.264649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-11-28 10:09:30.264655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-11-28 10:09:30.265552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14645 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n",
      "Training model has started\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Training images =  32\n",
      "Validation images =  8\n",
      "Test images =  8\n",
      "Number of epochs =  2\n",
      "Learning rate =  0.002\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 10:09:34.538697: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-11-28 10:09:34.539134: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2700000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 10:09:44.482668: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-11-28 10:09:44.940850: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2022-11-28 10:09:45.707784: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-11-28 10:09:46.143472: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-28 10:09:47.578719: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-11-28 10:09:47.578781: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 19s 2s/step - loss: 0.8695 - acc: 0.5708 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - 5s 593ms/step - loss: 0.9261 - acc: 0.5583 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Valloss, val acc =  [0.6936615705490112, 0.5]\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "computing embeddings of test images\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Test loss, Test accuracy =  [0.7376356720924377, 0.20000000298023224]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Training and evaluation has finished!\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# Train the embedding model and evaluate it on validation set. Precompute the embeddings from the test set\n",
    "# and evaluate the performance on the verification task using 2n pairs (n matches and n non-matches).\n",
    "ModelTraining(TIms,TLabs,VIms,VLabs,TeIms,TeLabs,p2,Lr,lr,pm,n,shp,Epochs,compress_horizontally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cee023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
