{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab715521",
   "metadata": {},
   "source": [
    "We used four different datasets (species) to validate our developed approach and thus ran four separate models using the same architectures (one model per dataset). The script **Individual_ID_Triplet_NN_helper.py** contains all the required implementations to run the triplet loss neural network. Here we provide four subsets of the datasets we used in the paper and csv files containing image names and their corresponding IDs where images having the same ID originate from the same individual, otherwise two different individuals. For e.g. p2 and p1 refer to the directory containing whale image examples and the csv file containing their IDs.\n",
    "\n",
    "Parameters\n",
    "\n",
    "1. nIms: The most number of images from each individual used in the baatch of images,\n",
    "2. shp: The size of the input image,\n",
    "3. augmentation: The number of augmented versions of the original images to be generated during online data augmentation,\n",
    "4. Lr: Maximum learning rate,\n",
    "5. lr: Minimum learning rate,\n",
    "6. n: An equal number of matches and non-matches to generate from the test set for the sake of evaluating the verification task,\n",
    "7. Epochs: The number of iteration to train the model,\n",
    "8. compress_horizontal: A boolean parameter only set to **True** for the whale dataset.\n",
    "9. pm: Path for saving weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Individual_ID_Triplet_NN_helper import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"whale_image_examples_IDs.csv\"\n",
    "p2 = \"whale_image_examples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nIms = 4\n",
    "shp   = (384,384,1)\n",
    "augmentation = 4\n",
    "Lr = 2e-3\n",
    "lr = 5e-4\n",
    "pm = \"Path_save_weights/test.h5\"\n",
    "n = 5\n",
    "Epochs = 10\n",
    "compress_horizontally = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structuring\n",
    "Ds = DataStructuring(p1,p2,nIms)\n",
    "Imgs,Labels = Ds.Im2Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data spliting into training, validation, and test sets\n",
    "sp = 8\n",
    "v = 16\n",
    "TIms,TLabs = Imgs[:sp],Labels[:sp]\n",
    "VIms,VLabs = Imgs[sp:v],Labels[sp:v]\n",
    "TeIms,TeLabs = Imgs[v:],Labels[v:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041fc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation, creating copies of the original sets and modify them during training\n",
    "# using an affine transformation\n",
    "TIms, TLabs = Augmentation(TIms,TLabs,augmentation,nIms).Im2Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the embedding model and evaluate it on validation set. Precompute the embeddings from the test set\n",
    "# and evaluate the performance on the verification task using 2n pairs (n matches and n non-matches).\n",
    "ModelTraining(TIms,TLabs,VIms,VLabs,TeIms,TeLabs,p2,Lr,lr,pm,n,shp,Epochs,compress_horizontally)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
