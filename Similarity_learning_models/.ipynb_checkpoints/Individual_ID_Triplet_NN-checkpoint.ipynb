{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38ab594a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 15:15:40.257105: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from Individual_ID_Triplet_NN_helper import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bac05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5cce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"toad_Image_examples_IDs.csv\"\n",
    "p2 = \"toad_Image_examples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950c4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nIms = 16\n",
    "shp   = (384,384,1)\n",
    "augmentation = 4\n",
    "Lr = 2e-3\n",
    "lr = 5e-4\n",
    "pm = \"EMMA/\"\n",
    "n = 5\n",
    "Epochs = 10\n",
    "compress_horizontally = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56bead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structuring\n",
    "Ds = DataStructuring(p1,p2,nIms)\n",
    "Imgs,Labels = Ds.Im2Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a035f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data spliting into training, validation, and test sets\n",
    "sp = 8\n",
    "v = 16\n",
    "TIms,TLabs = Imgs[:sp],Labels[:sp]\n",
    "VIms,VLabs = Imgs[sp:v],Labels[sp:v]\n",
    "TeIms,TeLabs = Imgs[v:],Labels[v:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041fc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation, creating copies of the original sets and modify them during training\n",
    "# using an affine transformation\n",
    "TIms, TLabs = Augmentation(TIms,TLabs,augmentation,nIms).Im2Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd3e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 130.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 24 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-11-25 15:15:55.251629: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-25 15:15:55.297682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-11-25 15:15:55.297723: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-25 15:15:55.303922: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-11-25 15:15:55.303989: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-25 15:15:55.306386: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-25 15:15:55.306900: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-25 15:15:55.307676: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-11-25 15:15:55.308757: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-11-25 15:15:55.309095: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-11-25 15:15:55.309595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-25 15:15:55.310390: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 15:15:55.321662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-11-25 15:15:55.322060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-25 15:15:55.322101: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-25 15:15:55.893687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-25 15:15:55.893710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-11-25 15:15:55.893716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-11-25 15:15:55.894562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30995 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n",
      "Training model has started\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Training images =  32\n",
      "Validation images =  8\n",
      "Test images =  8\n",
      "Number of epochs =  10\n",
      "Learning rate upper limit =  0.002\n",
      "Learning rate lower limit =  0.0005\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 15:16:11.876021: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-11-25 15:16:11.876661: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2700000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 15:16:17.754914: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-11-25 15:16:24.553655: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202\n",
      "2022-11-25 15:16:28.740316: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-11-25 15:16:29.396927: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 22s 22s/step - loss: 1.0122 - val_loss: 1.3499\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6720 - val_loss: 1.4190\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6613 - val_loss: 1.5887\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 0.4102 - val_loss: 1.8836\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5435 - val_loss: 2.1736\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.2943 - val_loss: 2.4918\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1473 - val_loss: 2.5846\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.1981 - val_loss: 2.7445\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 0.0637 - val_loss: 2.8491\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0203 - val_loss: 2.9430\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      "Val loss =  1.3498964309692383\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "computing embeddings of test images\n",
      "\n",
      "1/1 [==============================] - 1s 758ms/step\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "computing Evaluation Metrics\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Number of test pairs =  10\n",
      "\n",
      "Recall =  0.8\n",
      "\n",
      "Precision =  0.6667\n",
      "\n",
      "F1 score =  0.7273\n",
      "\n",
      "Accuracy =  0.7\n",
      "\n",
      "AUC =  0.68\n",
      "\n",
      "Optimized threshold =  1.0958\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Training and evaluation has finished!\n",
      "\n",
      "======================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the embedding model and evaluate it on validation set. Precompute the embeddings from the test set\n",
    "# and evaluate the performance on the verification task using 2n pairs\n",
    "ModelTraining(TIms,TLabs,VIms,VLabs,TeIms,TeLabs,p2,Lr,lr,pm,n,shp,Epochs,compress_horizontally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a99f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
