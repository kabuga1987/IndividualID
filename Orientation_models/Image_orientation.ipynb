{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781842ab",
   "metadata": {},
   "source": [
    "We use two independante datasets to validate the orientation model which is tasked with deciding which side of the animal was photographed. We implemented two separate models, i.e. each one per dataset using the same architecture, the only difference is the number of nodes in the output layer which is 2 (left and right orientation) for bottlenose dolphins and 3 (left, front-head, and right orientation) for harbour seals. Here we provide image examples and their orientation sides. For e.g., p1 and p2 are paths to harbour seal image examples and their orientation sides. The script **Image_orientation** constains all the necessary implementation for running the orientation model.\n",
    "\n",
    "Parameters\n",
    "\n",
    "1. Lr: The learning rate,\n",
    "2. shp: The size of the input image,\n",
    "3. Epochs: The number of iteration to train the model,\n",
    "4. out_nodes: The number nodes to use in the output layer,\n",
    "5. pw: Path to where weights will be save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the script containing the required implementations\n",
    "from Image_orientation import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a294d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"seal_image_examples/\"\n",
    "p2 = \"seal_image_example_sides.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "Lr = 1e-4\n",
    "pw = \"Path_save_weights.h5\"\n",
    "shp = (384,384,1)\n",
    "Epochs = 2\n",
    "out_nodes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structuring and label encoding\n",
    "dp = DataPreparation(p2,out_nodes)\n",
    "Imgs,Labels = dp.LabEncoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data\n",
    "TIms,TLabs = Imgs[:2],Labels[:2]\n",
    "VIms,VLabs = Imgs[2:4],Labels[2:4]\n",
    "TeIms,TeLabs = Imgs[4:],Labels[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ba2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000af3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "ModelTraining(TIms,TLabs,VIms,VLabs,TeIms,TeLabs,p1,Lr,pw,shp,Epochs,out_nodes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e0ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
